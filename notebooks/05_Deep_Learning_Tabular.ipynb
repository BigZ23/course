{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/tds2023-24/course/blob/main/notebooks/05_Deep_Learning_Tabular.ipynb\n",
    "\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class='bar_title'></div>\n",
    "\n",
    "*Topics in Data Science 2*\n",
    "\n",
    "# Deep Learning on Tabular Data\n",
    "\n",
    "Gunther Gust & Justus Ameling<br>\n",
    "Chair of Enterprise AI <br>\n",
    "Data Driven Decisions Group &<br>\n",
    "Center for Artificial Intelligence and Data Science (CAIDAS)\n",
    "\n",
    "Winter Semester 23/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/d3.png\" style=\"width:20%; float:left;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Credits__\n",
    "\n",
    "<img src=\"https://github.com/GuntherGust/tds2_data/blob/main/images/05/fastaiCover.jpg?raw=true\" width=\"500\" align=\"right\"/>\n",
    "\n",
    "In the next lectures we will dive into Deep Learning using ressources from the book of \n",
    "**Jeremy Howard and Sylvian Gugger: \"Deep Learning for Coders with Fastai and PyTorch: AI Applications without a PhD.\" (2020).**\n",
    "\n",
    "It's freely available as interactive [Jupyter Notebook](https://github.com/fastai/fastbook) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Materials also taken from:\n",
    "- https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb\n",
    "- https://www.fast.ai/2018/04/29/categorical-embeddings/\n",
    "- https://confusedcoders.com/data-science/deep-learning/how-to-apply-deep-learning-on-tabular-data-with-fastai "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of 2015, the [Rossmann sales competition](https://www.kaggle.com/c/rossmann-store-sales) ran on Kaggle. Competitors were given a wide range of information about various stores in Germany, and were tasked with trying to predict sales on a number of days. The goal was to help the company to manage stock properly and be able to satisfy demand without holding unnecessary inventory. The official training set provided a lot of information about the stores. It was also permitted for competitors to use additional data, as long as that data was made public and available to all participants.\n",
    "\n",
    "One of the gold medalists used deep learning, in one of the earliest known examples of a state-of-the-art deep learning tabular model. Their method involved far less feature engineering, based on domain knowledge, than those of the other gold medalists. The paper, [\"Entity Embeddings of Categorical Variables\"](https://arxiv.org/abs/1604.06737) describes their approach. The authors state:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Entity embedding not only **reduces memory usage** and **speeds up neural networks compared with one-hot encoding**, but more importantly by **mapping similar values close to each other in the embedding space** it reveals the intrinsic properties of the categorical variables... \n",
    "\n",
    "> [It] is especially useful for datasets with lots of **high cardinality features**, where other methods tend to overfit... As entity embedding defines a distance measure for categorical variables it can be used for visualizing categorical data and for data clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Categorical Embedding Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have a look at the examples from the paper [\"Entity Embeddings of Categorical Variables\"](https://arxiv.org/abs/1604.06737) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**State embeddings and map**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"State embeddings and map\" width=\"50%\" caption=\"State embeddings and map (courtesy of Cheng Guo and Felix Berkhahn)\" id=\"state_emb\" src=\"https://github.com/GuntherGust/tds2_data/blob/main/images/05/storeEmbedding.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left is a plot of the embedding matrix for the possible values of the `State` category. For a categorical variable we call the possible values of the variable its \"levels\" (or \"categories\" or \"classes\"), so here one level is \"Berlin,\" another is \"Hamburg,\" etc. On the right is a map of Germany. The actual physical locations of the German states were not part of the provided data, yet the model itself learned where they must be, based only on the behavior of store sales!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Store Distances**\n",
    "\n",
    "The distance between store embeddings against the actual geographic distance between the stores - they match very closely!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Store distances\" width=\"50%\" caption=\"Store distances (courtesy of Cheng Guo and Felix Berkhahn)\" id=\"store_emb\" src=\"https://github.com/GuntherGust/tds2_data/blob/main/images/05/embeddingDistance.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Date Embedding**\n",
    "\n",
    "Days and months that are near each other on the calendar ended up close as embeddings too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"Date embeddings\" width=\"50%\" caption=\"Date embeddings\" id=\"date_emb\" src=\"https://github.com/GuntherGust/tds2_data/blob/main/images/05/dateEmbedding.png?raw=true\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we train such embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__What are neural networks?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "- Biological neural networks have interconnected neurons with dendrites that receive inputs, then based on these inputs they produce an output signal through an axon to another neuron\n",
    "- Artificial Neural Networks (ANN) are a machine learning framework that attempts to mimic the learning pattern of natural biological neural networks\n",
    "- The creation of ANN begins with the most basic form, a single perceptron\n",
    "\n",
    "<img src=\"./images/05/DALL·E 2023-10-07 15.23.07.png\" width=\"30%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "Developed by Frank Rosenblatt in 1957\n",
    "- Perceptrons have one or more weighted inputs, a bias, an activation function, and a single output\n",
    "- A perceptron receives inputs, multiplies them by some weight, and then passes them into an activation function to produce an output\n",
    "- The key idea is to “fire” / activate the neuron only if a sufficiently strong input signal is detected\n",
    "\n",
    "<img src=\"https://github.com/GuntherGust/tds2_data/blob/main/images/05/NetworkStep.png?raw=true\" width=\"50%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Different Activation Functions and their Graphs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://github.com/GuntherGust/tds2_data/blob/main/images/05/activationFunction.png?raw=true\" width=\"50%\"/>\n",
    "\n",
    "[Image Source](https://medium.com/@shrutijadon10104776/survey-on-activation-functions-for-deep-learning-9689331ba092)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "ReLU is the most commonly used Activation Functions, because of its simplicity during backpropagation and its not computationally expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Multi-layer Perceptron aka. Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A MLP is composed of multiple layers of perceptrons \n",
    "\n",
    "<img src=\"https://github.com/GuntherGust/tds2_data/blob/main/images/05/network.png?raw=true\" style=\"width:80%\" />\n",
    "\n",
    "[Image Source](https://github.com/PetarV-/TikZ/tree/master/Multilayer%20perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Layers of a MLP__\n",
    "\n",
    "- Initial layer = input layer which is fed by the feature inputs\n",
    "- Last layer = output layer which creates the resulting outputs\n",
    "- Any layers in between are known as hidden layers because they do not directly “observe” the feature inputs or outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Universal approximation theorem__\n",
    "\n",
    "From Wikipedia:\n",
    "\n",
    "_\"In the mathematical theory of artificial neural networks, the universal approximation theorem states that a feed-forward network with __a single hidden layer__ containing a finite number of neurons can approximate continuous functions [...] when given appropriate parameters; however, it does not touch upon __the algorithmic learnability of those parameters__.\"_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training Neural Networks\n",
    "\n",
    "Learning is adjustment of the weights of the connections between perceptrons according to some modification rule. \n",
    "\n",
    "- The Backpropagation algorithm searches for weight values that minimize the total error of the network over the set of training examples\n",
    "\n",
    "It consists of the repeated application of the following two passes.\n",
    "\n",
    "- __Forward pass__: in this step the network is activated on one example and the error of (each neuron of) the output layer is computed\n",
    "- __Backward pass__: in this step the network error is used for updating the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Forward and Backward paths__\n",
    "\n",
    "<img src=\"https://github.com/GuntherGust/tds2_data/blob/main/images/05/ForwardBackwardPass.png?raw=true\" style=\"width:60%\" />\n",
    "\n",
    "[Image Source](https://medium.com/datathings/neural-networks-and-backpropagation-explained-in-a-simple-way-f540a3611f5e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__MLP Example__\n",
    "\n",
    "We will work with the same dataset as in the last lecture, a sample of the adult dataset which has some census information on individuals. Again, we'll use it to train a model to predict whether salary is greater than $50k or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'https://raw.githubusercontent.com/GuntherGust/tds2_data/main/data/adult.csv'\n",
    "adult_data = pd.read_csv(file_path)\n",
    "adult_data = adult_data.assign(salary=(adult_data['salary']=='>=50k').astype(int))\n",
    "y = adult_data['salary']\n",
    "X = adult_data.drop(columns=['salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute missing values (we will omit the categorical features here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_imputer = SimpleImputer()\n",
    "numCols = X.select_dtypes(['int', 'float']).columns.to_list()\n",
    "train_X_num = pd.DataFrame(simple_imputer.fit_transform(train_X[numCols]), columns=numCols, index=train_X.index)\n",
    "val_X_num = pd.DataFrame(simple_imputer.transform(val_X[numCols]), columns=numCols, index=val_X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Standardize numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_X_num_standardized = pd.DataFrame(scaler.fit_transform(train_X_num), columns=numCols, index=train_X.index)\n",
    "val_X_num_standardized = pd.DataFrame(scaler.transform(val_X_num), columns=numCols, index=val_X.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier()\n",
    "model.fit(train_X_num_standardized, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8260655939073824"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(val_X_num_standardized)\n",
    "accuracy_score(val_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Advantages of Multi-layer Perceptrons__\n",
    "\n",
    "- Capability to learn non-linear models.\n",
    "- Capability to learn models in real-time (on-line learning) using `partial_fit`\n",
    "\n",
    "__The disadvantages of Multi-layer Perceptrons__\n",
    "- MLP with hidden layers have a non-convex loss function where there exists more than one local minimum. Therefore different random weight initializations can lead to different validation accuracy.\n",
    "- MLP requires tuning a number of hyperparameters such as the number of hidden neurons, layers, and iterations.\n",
    "- MLP is sensitive to feature scaling.\n",
    "\n",
    "[from scikit-learn](https://scikit-learn.org/stable/modules/neural_networks_supervised.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Is this already deep learning?__\n",
    "\n",
    "From Wikipedia: \n",
    "\n",
    "_\"Deep learning [...] uses multiple layers to progressively extract higher level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits or letters or faces.\"_ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep Learning on Tabular Data with *fast.ai*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**The Mission of [fast.ai](https://www.fast.ai/about.html): Making neural nets uncool again**\n",
    "\n",
    "Deep learning is transforming the world. We are making deep learning easier to use and getting more people from all backgrounds involved through our:\n",
    "\n",
    "- [free courses for coders](http://course.fast.ai/)\n",
    "- software library: [fastai for PyTorch](http://docs.fast.ai/)\n",
    "- cutting-edge research\n",
    "- community\n",
    "\n",
    "The world needs everyone involved with AI, no matter how unlikely your background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, let's import everything we need for the tabular application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -Uqq fastai  # upgrade fastai on colab\n",
    "from fastai.tabular.all import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from <module> import *` means “I want access to all the names in <module> that I’m meant to have access to”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### *fast.ai* Datasets\n",
    "\n",
    "Tabular data usually comes in the form of a delimited file (such as .csv) containing variables of different kinds: text/category, numbers, and perhaps some missing values. \n",
    "\n",
    "*Fast.ai's* [external data functions](https://docs.fast.ai/data.external.html) provides several useful datasets that we might be interested in using in our models.\n",
    "\n",
    "We will work with the same dataset as in the last lecture, a sample of the __adult dataset__ which has some census information on individuals. Again, we'll use it to train a model to predict whether salary is greater than \\$50k or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('C:/Users/ggust/.fastai/data/adult_sample/adult.csv'),Path('C:/Users/ggust/.fastai/data/adult_sample/export.pkl'),Path('C:/Users/ggust/.fastai/data/adult_sample/models')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(url=URLs.ADULT_SAMPLE)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`untar_data()`downloads a dataset from `url` and unpacks it to `path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>101320</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>236746</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>10520</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>96185</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>112847</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>82297</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt     education  education-num  \\\n",
       "0   49            Private  101320    Assoc-acdm           12.0   \n",
       "1   44            Private  236746       Masters           14.0   \n",
       "2   38            Private   96185       HS-grad            NaN   \n",
       "3   38       Self-emp-inc  112847   Prof-school           15.0   \n",
       "4   42   Self-emp-not-inc   82297       7th-8th            NaN   \n",
       "\n",
       "        marital-status        occupation    relationship                 race  \\\n",
       "0   Married-civ-spouse               NaN            Wife                White   \n",
       "1             Divorced   Exec-managerial   Not-in-family                White   \n",
       "2             Divorced               NaN       Unmarried                Black   \n",
       "3   Married-civ-spouse    Prof-specialty         Husband   Asian-Pac-Islander   \n",
       "4   Married-civ-spouse     Other-service            Wife                Black   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country salary  \n",
       "0   Female             0          1902              40   United-States  >=50k  \n",
       "1     Male         10520             0              45   United-States  >=50k  \n",
       "2   Female             0             0              32   United-States   <50k  \n",
       "3     Male             0             0              40   United-States  >=50k  \n",
       "4   Female             0             0              50   United-States   <50k  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'adult.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Here all the information that will form our input is in the 14 first columns, and the dependent variable is the last column. We will split our input between two types of variables: categorical and continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### From data to dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastai uses [data loaders](https://docs.fast.ai/data.load.html) to get the data ready for training.\n",
    "\n",
    "A data loader usually combines a dataset and a sampler, and provides an iterable over the given dataset. [fastai](https://docs.fast.ai/data.load.html) includes a replacement for [Pytorch's DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) which is largely API-compatible, and adds a lot of useful functionality and flexibility.\n",
    "\n",
    "How do we create a data loader?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Categorical and continuous variables__\n",
    "\n",
    "- **Categorical variables** (like workclass or education) will be replaced by a category - a unique id that identifies them - before they are passed through an embedding layer.\n",
    "- **Continuous variables** (like age) will be normalized and then directly fed to the model.\n",
    "\n",
    "We can specify our categorical and continuous column names, as well as the name of the dependent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_names = 'salary'\n",
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Tabular data preprocessing__\n",
    "\n",
    "fast.ai contains classes that define [transformations](https://docs.fast.ai/tabular.core.html#TabularProc) for preprocessing dataframes of tabular data. Preprocessing includes things like\n",
    "\n",
    "- `Categorify`: replacing non-numerical variables by categories, i.e, their unique category id\n",
    "- `FillMissing`: filling missing values (default fill strategy: median)\n",
    "- `Normalize:` normalizing continuous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can define a list of Transforms that will be applied to our variables. Here we transform all categorical variables into categories. We also replace missing values for continuous variables by the median column value and normalize those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "procs = [FillMissing, Categorify, Normalize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the ordering of the tranformations matters. The typical sequence is to first handle missing values, then categorize categorical variables (including newly created categorial variables that indicate missingness), and finally normalize continuous variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Training and validation sets__\n",
    "\n",
    "To split our data into training and validation sets, we use valid indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([26464, 16134, 4747, 8369, 5741], dtype='int64')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, valid_idx = train_test_split(df.index, test_size=0.25, random_state = 0)\n",
    "train_idx[:5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Creating the DataLoader__\n",
    "\n",
    "Now we're ready to pass this information to a [TabularDataLoader](https://docs.fast.ai/tabular.data.html#TabularDataLoaders) to create the DataLoaders that we'll use for training. We will learn the details of `DataLoaders` class in the next lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, \n",
    "                                  y_names=y_names,\n",
    "                                  cat_names = cat_names,\n",
    "                                  cont_names = cont_names,\n",
    "                                  valid_idx=valid_idx,\n",
    "                                  procs = procs,\n",
    "                                 bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7) ['workclass','education','marital-status','occupation','relationship','race','education-num_na']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.cat_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can grab a mini-batch of data and take a look. `show_batch` shows a batch of data in a convenient way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "After being processed, the categorical variables are replaced by ids and the continuous variables are normalized. The codes corresponding to categorical variables are all put together, as are all the continuous variables.\n",
    "\n",
    "But how does the data exactly look like for our model? Let's have a look:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 6, 10,  5,  2,  2,  5,  1],\n",
       "         [ 5, 12,  5, 13,  2,  5,  1],\n",
       "         [ 5, 16,  5, 15,  2,  5,  1],\n",
       "         [ 5, 14,  5,  8,  2,  3,  1],\n",
       "         [ 5, 12,  1,  4,  5,  5,  1],\n",
       "         [ 5, 10,  3,  5,  6,  5,  1],\n",
       "         [ 5, 12,  5, 14,  4,  5,  1],\n",
       "         [ 5, 12,  3,  9,  6,  4,  1],\n",
       "         [ 5, 10,  3, 11,  1,  5,  1],\n",
       "         [ 5, 12,  3,  9,  1,  5,  1],\n",
       "         [ 5, 12,  3,  4,  1,  5,  1],\n",
       "         [ 5, 12,  3, 13,  1,  5,  1],\n",
       "         [ 3, 10,  3, 11,  1,  5,  1],\n",
       "         [ 5,  6,  3,  4,  1,  5,  1],\n",
       "         [ 5, 10,  5,  5,  2,  5,  1],\n",
       "         [ 7, 12,  3,  6,  1,  5,  1],\n",
       "         [ 6, 12,  3,  5,  1,  5,  1],\n",
       "         [ 5, 16,  5,  2,  2,  3,  1],\n",
       "         [ 1,  6,  5,  1,  3,  3,  1],\n",
       "         [ 5, 12,  1,  5,  2,  5,  1],\n",
       "         [ 3, 12,  6, 15,  4,  5,  1],\n",
       "         [ 3, 16,  1,  2,  5,  5,  1],\n",
       "         [ 5, 12,  3,  6,  1,  5,  1],\n",
       "         [ 5, 12,  5,  7,  5,  5,  1],\n",
       "         [ 5, 12,  5,  7,  3,  3,  1],\n",
       "         [ 5, 12,  1, 12,  2,  5,  1],\n",
       "         [ 5, 10,  5, 13,  2,  5,  1],\n",
       "         [ 5, 12,  5,  6,  4,  5,  1],\n",
       "         [ 1,  1,  3,  1,  6,  3,  1],\n",
       "         [ 5, 12,  3,  9,  1,  5,  1],\n",
       "         [ 6, 10,  6, 13,  2,  5,  1],\n",
       "         [ 5,  1,  1,  8,  5,  5,  1],\n",
       "         [ 5, 13,  5, 11,  2,  5,  1],\n",
       "         [ 5, 11,  3, 11,  1,  5,  1],\n",
       "         [ 5, 12,  3,  8,  1,  5,  2],\n",
       "         [ 6, 15,  3, 11,  1,  4,  1],\n",
       "         [ 5, 12,  1,  5,  5,  5,  1],\n",
       "         [ 5,  8,  5, 13,  5,  5,  2],\n",
       "         [ 5, 13,  1,  5,  2,  5,  1],\n",
       "         [ 5, 16,  6,  9,  5,  3,  1],\n",
       "         [ 5,  2,  5, 15,  4,  5,  1],\n",
       "         [ 5,  8,  6,  2,  2,  5,  1],\n",
       "         [ 5, 16,  5, 11,  3,  2,  1],\n",
       "         [ 7,  3,  3, 13,  6,  2,  1],\n",
       "         [ 3, 11,  3, 11,  6,  5,  1],\n",
       "         [ 5, 10,  3, 11,  6,  5,  1],\n",
       "         [ 5, 13,  1, 13,  2,  5,  1],\n",
       "         [ 5, 12,  5, 13,  4,  5,  1],\n",
       "         [ 1,  1,  5,  1,  4,  3,  1],\n",
       "         [ 2, 16,  5,  4,  2,  5,  1],\n",
       "         [ 5,  9,  3,  4,  1,  5,  1],\n",
       "         [ 5, 10,  7,  5,  2,  5,  1],\n",
       "         [ 5, 12,  5,  4,  2,  5,  1],\n",
       "         [ 8, 13,  3, 11,  1,  5,  1],\n",
       "         [ 5, 12,  3,  4,  1,  5,  1],\n",
       "         [ 5, 10,  3,  4,  1,  5,  1],\n",
       "         [ 5, 10,  3, 11,  1,  5,  1],\n",
       "         [ 5, 13,  1, 11,  2,  5,  1],\n",
       "         [ 7, 12,  3,  4,  1,  5,  1],\n",
       "         [ 5, 10,  5,  5,  2,  5,  1],\n",
       "         [ 5, 16,  3,  2,  1,  5,  1],\n",
       "         [ 5,  4,  5,  9,  4,  4,  1],\n",
       "         [ 5,  8,  1, 13,  5,  5,  1],\n",
       "         [ 5, 12,  1, 13,  2,  1,  1]]),\n",
       " tensor([[-0.9263,  0.7277,  1.1453],\n",
       "         [ 0.1726,  0.1683, -0.4203],\n",
       "         [-0.9995, -0.0753, -0.0289],\n",
       "         [-0.1937,  0.5917, -3.5515],\n",
       "         [-0.4867, -1.3882, -0.4203],\n",
       "         [-0.4135, -0.6665,  1.1453],\n",
       "         [-1.4391,  0.0860, -0.4203],\n",
       "         [-0.4867,  0.4933, -0.4203],\n",
       "         [ 0.7586, -1.0091,  1.1453],\n",
       "         [ 0.3191, -0.1352, -0.4203],\n",
       "         [-0.7798,  0.0129, -0.4203],\n",
       "         [ 2.2970,  0.8363, -0.4203],\n",
       "         [-0.4135, -0.6991,  1.1453],\n",
       "         [ 1.4912,  3.0788, -2.3773],\n",
       "         [-0.9995,  0.6453,  1.1453],\n",
       "         [ 0.9051, -0.8978, -0.4203],\n",
       "         [-0.5600, -1.3180, -0.4203],\n",
       "         [ 1.1982, -0.2912, -0.0289],\n",
       "         [ 2.0040, -0.7782, -2.3773],\n",
       "         [-0.0472, -1.1698, -0.4203],\n",
       "         [ 0.1726,  0.5556, -0.4203],\n",
       "         [-0.1937,  1.2217, -0.0289],\n",
       "         [-0.4135, -0.6313, -0.4203],\n",
       "         [-0.9995, -0.5593, -0.4203],\n",
       "         [-1.2926,  0.2215, -0.4203],\n",
       "         [ 2.2970,  4.2788, -0.4203],\n",
       "         [-0.7065,  1.3270,  1.1453],\n",
       "         [-0.5600,  0.6623, -0.4203],\n",
       "         [ 0.6854, -0.7239, -1.5945],\n",
       "         [ 1.8575, -0.7038, -0.4203],\n",
       "         [ 1.6377,  0.3557,  1.1453],\n",
       "         [ 0.0993, -0.8512, -1.5945],\n",
       "         [ 1.7109,  0.5958,  1.5367],\n",
       "         [-0.1937,  1.5791,  2.3195],\n",
       "         [ 0.5388,  1.3426, -0.0289],\n",
       "         [ 0.9784, -0.0726,  1.9281],\n",
       "         [-0.1205, -1.5353, -0.4203],\n",
       "         [-0.3402, -0.0221, -0.0289],\n",
       "         [ 0.4656, -0.7728,  1.5367],\n",
       "         [-0.4135, -0.4852, -0.0289],\n",
       "         [ 0.0993,  0.1128, -1.2031],\n",
       "         [ 0.7586, -0.9999,  0.7539],\n",
       "         [-1.2193, -0.7307, -0.0289],\n",
       "         [-0.5600, -0.2548, -0.8117],\n",
       "         [ 0.5388,  1.9770,  2.3195],\n",
       "         [-0.6332, -0.2559,  1.1453],\n",
       "         [ 0.3923, -0.0653,  1.5367],\n",
       "         [-1.4391,  1.7513, -0.4203],\n",
       "         [-1.5856,  1.4334, -1.5945],\n",
       "         [-0.6332,  1.2246, -0.0289],\n",
       "         [-0.0472, -0.3295,  0.3625],\n",
       "         [ 2.0772, -0.7957,  1.1453],\n",
       "         [-1.2926, -1.2985, -0.4203],\n",
       "         [ 0.1726, -1.4400,  1.5367],\n",
       "         [ 0.7586, -0.0348, -0.4203],\n",
       "         [-0.7798,  0.7002,  1.1453],\n",
       "         [-0.5600,  0.6023,  1.1453],\n",
       "         [ 0.9784,  0.1067,  1.5367],\n",
       "         [-0.7065, -0.2354, -0.4203],\n",
       "         [-0.9263, -0.9430,  1.1453],\n",
       "         [ 1.0516, -1.3418, -0.0289],\n",
       "         [-0.8530, -0.7182, -3.1601],\n",
       "         [ 0.0993,  0.0790,  0.7539],\n",
       "         [-0.7065, -1.5073, -0.4203]]),\n",
       " tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]], dtype=torch.int8))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = dls.one_batch()\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: As we pick out batches randomly, the output of `show_batch` may not correspond to the output below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Once we have our data ready in `DataLoaders`, we just need to create a model to then define a Learner and start training. \n",
    "\n",
    "This is typically composed of following steps :\n",
    "\n",
    "1. __Create Learner__: Create an appropriate learner for data. A learner creates a neural network for us.\n",
    "2. __Find the learning rate__: We need to find a suitable learning rate for our training\n",
    "3. __Fit the model__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Create Learner__\n",
    "\n",
    "The fastai library has a flexible and powerful `TabularModel`. The `tabular_learner` will automatically create a `TabularModel` suitable for your data and infer the right loss function. See the tabular [tutorial](https://docs.fast.ai/tutorial.tabular) for an example of use in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(dls, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's print a summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TabularModel (Input shape: 64 x 7)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     64 x 6              \n",
       "Embedding                                 60         True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 8              \n",
       "Embedding                                 136        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 5              \n",
       "Embedding                                 40         True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 8              \n",
       "Embedding                                 128        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 5              \n",
       "Embedding                                 35         True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 4              \n",
       "Embedding                                 24         True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 3              \n",
       "Embedding                                 9          True      \n",
       "Dropout                                                        \n",
       "BatchNorm1d                               6          True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 200            \n",
       "Linear                                    8400       True      \n",
       "ReLU                                                           \n",
       "BatchNorm1d                               400        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 100            \n",
       "Linear                                    20000      True      \n",
       "ReLU                                                           \n",
       "BatchNorm1d                               200        True      \n",
       "____________________________________________________________________________\n",
       "                     64 x 2              \n",
       "Linear                                    202        True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 29,640\n",
       "Total trainable params: 29,640\n",
       "Total non-trainable params: 0\n",
       "\n",
       "Optimizer used: <function Adam at 0x000001FF425A14C0>\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - CastToTensor\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visualizing the model graph with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard is a tool for providing the measurements and visualizations needed during the machine learning workflow. It enables \n",
    "\n",
    "- tracking experiment metrics like loss and accuracy, \n",
    "- visualizing the model graph, \n",
    "- projecting embeddings to a lower dimensional space, \n",
    "- and much more.\n",
    "\n",
    "Let's load the TensorBoard notebook extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The SummaryWriter class is your main entry to log data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Create a writer (for later logging the model and visualizing it in tensorboard) in the directory \"tb-tabular\"\n",
    "writer = SummaryWriter('tb-tabular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Write model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch one batch of data\n",
    "batch = dls.one_batch() #alternatively: next(iter(dls.train))\n",
    "# load the model to the cpu and pass some instances of the batch through it (this is necessary for the writer to log the computational graph)\n",
    "writer.add_graph(learn.model.cpu(), batch[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Start TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9776), started 0:58:29 ago. (Use '!kill 9776' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1056766c14f03dc7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1056766c14f03dc7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard providing the previously specified directory\n",
    "%tensorboard --logdir tb-tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of displaying tensorboard in the jupyter notebook cell, it may be better to open it in a new browser tab using \"localhost:<port>\", e.g \"localhost:6006\" in the address bar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Train the model\n",
    "\n",
    "__Find the learning rate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.001737800776027143)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We typically find the point where the slope is steepest. \n",
    "\n",
    "We will learn more about the Learning Rate finder and 1cycle policy, but here are some excellent resources that offer explanation: \n",
    "* https://fastai1.fast.ai/callbacks.one_cycle.html\n",
    "* https://sgugger.github.io/the-1cycle-policy.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Fit the model__ based on selected learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.358562</td>\n",
       "      <td>0.352830</td>\n",
       "      <td>0.835155</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.353478</td>\n",
       "      <td>0.352565</td>\n",
       "      <td>0.831593</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.366343</td>\n",
       "      <td>0.347124</td>\n",
       "      <td>0.835524</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.359944</td>\n",
       "      <td>0.346312</td>\n",
       "      <td>0.837612</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.330443</td>\n",
       "      <td>0.345688</td>\n",
       "      <td>0.838226</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, lr_max=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then have a look at some predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.612106</td>\n",
       "      <td>1.024965</td>\n",
       "      <td>-0.420295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.193712</td>\n",
       "      <td>0.619641</td>\n",
       "      <td>1.536692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.926274</td>\n",
       "      <td>-0.372728</td>\n",
       "      <td>-0.028898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.292554</td>\n",
       "      <td>-0.659661</td>\n",
       "      <td>-0.028898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.413480</td>\n",
       "      <td>1.795872</td>\n",
       "      <td>-0.420295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.779761</td>\n",
       "      <td>0.249271</td>\n",
       "      <td>1.145294</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.758618</td>\n",
       "      <td>0.723089</td>\n",
       "      <td>-0.420295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.685362</td>\n",
       "      <td>0.213071</td>\n",
       "      <td>-0.420295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.340224</td>\n",
       "      <td>-0.149313</td>\n",
       "      <td>1.536692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Get predictions__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can use the `Learner.predict` method to get predictions. In this case, we need to pass the row of a dataframe that has the same names of categorical and continuous variables as our training or validation dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row, clas, probs = learn.predict(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#na#</td>\n",
       "      <td>#na#</td>\n",
       "      <td>#na#</td>\n",
       "      <td>#na#</td>\n",
       "      <td>#na#</td>\n",
       "      <td>#na#</td>\n",
       "      <td>False</td>\n",
       "      <td>49.0</td>\n",
       "      <td>101320.002139</td>\n",
       "      <td>12.0</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "age                                49\n",
       "workclass                     Private\n",
       "fnlwgt                         101320\n",
       "education                  Assoc-acdm\n",
       "education-num                    12.0\n",
       "marital-status     Married-civ-spouse\n",
       "occupation                        NaN\n",
       "relationship                     Wife\n",
       "race                            White\n",
       "sex                            Female\n",
       "capital-gain                        0\n",
       "capital-loss                     1902\n",
       "hours-per-week                     40\n",
       "native-country          United-States\n",
       "salary                          >=50k\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor([0.7772, 0.2228]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clas, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Calculate performance metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [0.34606632590293884,0.8367522358894348]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... shows the validation loss and the validation metric (accuracy). \n",
    "We can manually compute this as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.836752241739344"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs, val_y = learn.get_preds(ds_idx=1)\n",
    "preds = np.argmax(probs, axis=1)\n",
    "accuracy_score(val_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To get prediction on a new dataframe, you can use the `test_dl` method of the DataLoaders. That dataframe does not need to have the dependent variable in its column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df.copy()\n",
    "test_df.drop(['salary'], axis=1, inplace=True)\n",
    "dl = learn.dls.test_dl(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Show rows result of predictions on the dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7772, 0.2228],\n",
       "         [0.6338, 0.3662],\n",
       "         [0.8478, 0.1522],\n",
       "         ...,\n",
       "         [0.7632, 0.2368],\n",
       "         [0.9060, 0.0940],\n",
       "         [0.9392, 0.0608]]),\n",
       " None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.get_preds(dl=dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is a scope of improving the deep learning model here. However this is not bad at all, without any feature engineering and network tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Embeddings for Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A key technique to making the most of deep learning for tabular data is to use embeddings for your categorical variables. This approach allows for __relationships between categories__ to be captured.\n",
    "\n",
    "Examples:\n",
    "- Saturday and Sunday may have similar behavior, and maybe Friday behaves like an average of a weekend and a weekday. \n",
    "-  Similarly, for zip codes, there may be patterns for zip codes that are geographically near each other, and for zip codes that are of similar socio-economic status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Applying Embeddings for Categorical Variables\n",
    "\n",
    "When working with categorical variables, we will represent each category by a vector of floating point numbers (the values of this representation are learned as the network is trained).\n",
    "\n",
    "For instance, a 4-dimensional version of an embedding for day of week could look like:\n",
    "\n",
    "__Sunday\t [.8, .2, .1, .1]__<br>\n",
    "__Monday\t[.1, .2, .9, .9]__<br>\n",
    "__Tuesday\t[.2, .1, .9, .8]__\n",
    "\n",
    "Here, Monday and Tuesday are fairly similar, yet they are both quite different from Sunday. \n",
    "\n",
    "Again, this is a toy example. In practice, our neural network would learn the best representations for each category while it is training, and each dimension (or direction, which doesn’t necessarily line up with ordinal dimensions) could have multiple meanings. Rich relationships can be captured in these distributed representations. \n",
    "\n",
    "The choice of the dimensions of the embeddings depends on many factors, such as training set size, complexity of the learning task and computational resources available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Visualizing Embeddings with Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Export embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "for i, emb in enumerate(learn.model.embeds):\n",
    "    emb_name = learn.dls.cat_names[i]\n",
    "    writer.add_embedding(emb.weight.data, metadata=learn.dls.classes[emb_name],\n",
    "                         global_step=i, tag=emb_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Finally, start tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9776), started 0:22:10 ago. (Use '!kill 9776' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-16957a376bbe2ea7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-16957a376bbe2ea7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tb-tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "___Colab Workaround___\n",
    "\n",
    "In Colab the dynamic tensorborad plugin isn’t supported yet, but you can still access the data and visualize the embeddings somewhere else: \n",
    "\n",
    "1. Download the desired embedding file (*tensors.tsv*) and metadata \n",
    "2. Upload the files on the official Tensorflow [Embedding Projector](https://projector.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "For analyzing time series and tabular data, deep learning has recently been making great strides. However, deep learning is generally used as part of an **ensemble of multiple types** of model. \n",
    "\n",
    "- If you already have a system that is using random forests or gradient boosting machines, then switching to or adding deep learning may not result in any dramatic improvement. \n",
    "- Deep learning does greatly increase the variety of columns that you can include\n",
    "    - columns containing natural language (book titles, reviews, etc.), \n",
    "    - high-cardinality categorical columns (i.e., something that contains a large number of discrete choices, such as zip code or product ID). \n",
    "- Deep learning models generally take longer to train than random forests or gradient boosting machines, although this is changing thanks to libraries such as [RAPIDS](https://rapids.ai/), which provides GPU acceleration for the whole modeling pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Final Notes\n",
    "\n",
    "* The material of this lecture is very advanced if you are not familiar to neural networks\n",
    "* You may be able to complete the course without diving deeper into them\n",
    "* However, to get most out of this class (and prepare yourself to become a data scientists), we highly recommend to check out the additional material provided. In particular:\n",
    "    * the materials and courses offeerd by [fastai](https://www.fast.ai/about.html)\n",
    "    * The book: Jeremy Howard and Sylvian Gugger (2020), \"Deep Learning for Coders with Fastai and PyTorch: AI Applications without a PhD.\" (2020). It's freely available as interactive [Jupyter Notebook](https://github.com/fastai/fastbook) \n",
    "    * Also Andrew NGs [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning?utm_medium=sem&utm_source=gg&utm_campaign=B2C_EMEA_deep-learning_deeplearning-ai_FTCOF_specializations_country-DE&campaignid=20416373453&adgroupid=155810822830&device=c&keyword=deep%20learning%20specialization&matchtype=b&network=g&devicemodel=&adposition=&creativeid=667829385242&hide_mobile_promo&gclid=Cj0KCQiAr8eqBhD3ARIsAIe-buNiwv5lVHgaI7bjlWFq52LxRgQNdlvNCevnV_33f_ZX8Dc4wKwLIUEaAiTCEALw_wcB) is a great course for learning more about the theory behind neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/d3.png\" style=\"width:50%; float:center;\" />"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "rise": {
   "enable_chalkboard": false,
   "overlay": "<div class='background'></div><div class='header'>WS 23/24</br>TDS 2</div><div class='logo'><img src='images/d3logo.png'></div><div class='bar'></div>",
   "scroll": true,
   "slideNumber": "h.v"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
